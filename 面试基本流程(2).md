String和StringBuffer、StringBuilder的区别是什么？

可变性

String类中使用字符数组保存字符串，private　final　char　value[]，所以 string对象是不可变的。StringBuilder与StringBuffer都继承自

AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串，char[] value，这两种对象都是可变的。线程安全性

String中的对象是不可变的，也就可以理解为常量，线程安全。

AbstractStringBuilder是StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作，如expandCapacity、append、insert、indexOf等公共方法。StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。

性能

每次对String 类型进行改变的时候，都会生成一个新的String对象，然后将指针指向新的String 对象。StringBuffer每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用StirngBuilder 相比使用StringBuffer 仅能获得10%~15% 左右的性能提升，但却要冒多线程不安全的风险。

对于三者使用的总结

如果要操作少量的数据用 = String 单线程操作字符串缓冲区 下操作大量数据 = StringBuilder 多线程操作字符串缓冲区 下操作大量数据 = StringBuffer

怎么保证线程安全？

锁升级过程？

synchronized、volatile？

java内存模型？

juc   jvm

java中fail-fast 和 fail-safe的区别

并发容器CopyOnWrite

looks体系，AQS？CAS？乐观锁 悲观锁

数据库锁，行锁，表锁，共享锁，Gap锁(间隙锁)，Innodb锁机制:*Next*-*Key* Lock

数据库隔离级别

数据库索引 聚簇非聚簇 最左前缀

数据库索引是怎么实现的

分布式锁 数据库 redis zk

分布式缓存

分布式CAP

BASE理论

分布式数据一致性

分布式事务

中间件



计划

网约车，springcloud项目 完善简历项目 3.2

分布式问题，3.4

dubbo，springcloud，中间件，redis  面试题3.6

springmvc，springboot 源码3.9

jvm juc io 集合 设计模型 基础 3.15

3.15end





# 1.Gc

跟可达算法、标记清除算法，标记复制算法、老年带也有gc、标记整理，老年代不常gc
在jvm中堆的分区有三块区域，青年代、老年代、永久带，永久带在jdk1.8之后就被取消了，变成元空间了，元空间功能和永久代类似。唯一到的区别是，永久代使用的是JVM的堆内存空间，而元空间使用的是物理内存。重点的话就是它的伊甸园和老年代，我们新创建的对象会先都放在伊甸园里，伊甸园里的对象到达一定的程度之后就会触发gc（跟可达算法），触发gc的时候会把没有引用指向的对象标记出来，说明这些对象就已近称为垃圾了，利用标记清除算法回收掉，会先利用标记复制算法把不是垃圾的对象放在幸存区1里面，然后直接清空伊甸园，然后我们新new的对象又会加到伊甸园里面来，有了垃圾的话还是进行上述的一系列操作，来到幸存区1的对象有会加一个年龄，如果对象年龄到了15岁之后就会加到老年代中，老年代也会进行gc，利用标记整理算法进行gc。然后会大对象会放入永久带。
大对象会放在永久带
永久代和元空间：永久代是一片连续的堆空间、两者最大的区别是元空间使用本地内存，而永久代使用的是JVM的内存，

# 1.GC收集器有哪些？

串行垃圾回收器（Serial Garbage Collector）

并行垃圾回收器（Parallel Garbage Collector）

并发标记扫描垃圾回收器（CMS Garbage Collector）

G1垃圾回收器（G1 Garbage Collector）

# 2.类加载的机制

JVM 把描述类的数据从 .class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的 Java 类型，

#### 类的生命周期

类的生命周期总共分为7个阶段：加载、验证、准备、解析、初始化、使用和卸载。其中验证、准备、解析三个步骤又可统称为连接。
加载、验证、准备、初始化和卸载五个步骤的顺序都是确定的，解析阶段在某些情况下有可能发生在初始化之后，这是为了支持 Java 语言的运行期绑定的特性。



# 2.**JVM参数设置：** 

-Xmx：设置JVM最大可用内存为3550M。 

-Xms：设置JVM初始内存为3550m。

-Xmn：设置青年代大小。

-Xss：设置每个线程的堆栈大小。

-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4

-XX:MaxPermSize=16m:设置持久代大小为16m。 

# 2、innodb和myasam的区别

1）InnoDB支持事务，MyISAM不支持，这一点是非常之重要。事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。
2）MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用
3）InnoDB支持外键，MyISAM不支持
4）从MySQL5.5.5以后，InnoDB是默认引擎
5）InnoDB不支持FULLTEXT类型的索引
6）InnoDB中不保存表的行数，如select count() from table时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时MyISAM也需要扫描整个表
7）对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引
8）清空整个表时，InnoDB是一行一行的删除，效率非常慢。MyISAM则会重建表
9）InnoDB支持行锁（某些情况下还是锁整表，如 update table set a=1 where user like ‘％lee％’。



# 2、Mysql的锁

## 概述

​    相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。

MySQL大致可归纳为以下3种锁：

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

 

在使用MyIsam时，我们只可以使用表级锁，而MySQL的表级锁有两种模式：

表共享锁（Table Read Lock）和表独占写锁（Table Write Lock），他们在工作时表现如下：

- 对某一个表的读操作，不会阻塞其他用户对同一表请求，但会阻塞对同一表的写请求；
- 对MyISAM的写操作，则会阻塞其他用户对同一表的读和写操作；
- MyISAM表的读操作和写操作之间，以及写操作之间是串行的。

当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。

# 2.Mysql事务与索引

## 20、如何避免死锁？ 

1. ### 加锁顺序

按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁(并对这些锁做适当的排序)，但总有些时候是无法预知的。

1. ### 加锁时限

另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。

### 3.死锁检测

每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。

### 事务

事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。

在并发情况下，多个事务去操作同一个数据时，会发生一些问题，比如说脏读、不可重复读、幻读的等问题，我们可以设置不同的隔离级别来解决这些问题k；

事务的隔离级别分为4个阶段：读未提交、读已提交（可以解决脏读）、可重复度（可以解决不可重复读）、串行化（可以解决任何问题，包括幻读，但是效率会非常低）；

### 索引

  **1、普通索引**

普通索引是最基本的索引，它没有任何限制，值可以为空；仅加速查询。可以通过以下几种方式来创建或

  **2、唯一索引**

唯一索引与普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。简单来说：唯一索引是加速查询 + 列值唯一（可以有null）。

  **3、主键索引**

主键索引是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。简单来说：主键索引是加速查询 + 列值唯一（不可以有null）+ 表中只有一个。

  **4、组合索引**

组合索引指在多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。

  **5、全文索引**
全文索引主要用来查找文本中的关键字，而不是直接与索引中的值相比较。

 **6、聚簇索引**

叶子节点存的是数据

 **7、非聚簇索引**

叶子节点存的是地址

### 索引失效

1. is null，is not null，会让索引失效，mysql的引擎是innodb，这个引擎只支持b树索引，树里不可能有null，如果是字符串判它是不是“ ”，如果是数字类型，判断它是不是0，
2. != 也会索引失效，替换成范围查询，换成两条sql（小于0和大于0），
3. or
4. 左模糊也会索引失效，8前面有没有东西不知道，插件，对数据库进行分词分段查询
5. where不要用表达式，id-2=3,
6. 避免在where子句中进行函数操作，调方法，
7. extends关键字代替in，判断存不存在，拿小括号里的和数据库的对比
8. 复合索引，指一个索引可以套在很多列上，三个列同时引用这个索引，先加到最开始的这个列上，然后后面的列复制它的算法
9. 没有意义的查询，where1=1
10. 索引加到有意义的列，性别，男女
11. 索引不是越多越好，索引占空间，索引上限6个，一张表里一般就三个，
12. 尽量使用数字型字段，1，0代表男女
13. 尽量使用varchar，可以理解成stringbuffer，char就是string
14. 避免频繁的创建和删除表
15. 单次给应用程序返回大量数据，分页查询数据量就变小了

# 3.数据库的优化

1、选取最适用的字段属性

在定义邮政编码这个字段时，如果将其设置为CHAR(255),显然给数据库增加了不必要的空间，甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了

2、使用连接（JOIN）来代替子查询(Sub-Queries)

3、使用联合(UNION)来代替手动创建的临时表

4、使用外键来维护数据库的关系

5、用EXplain(执行计划)来进行sql分析，有查询慢的，适合加索引的就把索引加上

6、优化的查询语句

在搜索字符型字段时，我们有时会使用LIKE关键字和通配符

但是如果换用下面的查询，返回的结果一样，但速度就要快上很多：





索引失效

```
SELECT * FROM books WHERE name＞="MySQL"and name＜"MySQM"
```

# 4.SpringBoot启动流程

SpringApplication的run方法做了什么？

1. 创建一个StopWatch并执行start方法，这个类主要记录任务的执行时间
2. 配置Headless属性，Headless模式是在缺少显示屏、键盘或者鼠标时候的系统配置
3. 在文件META-INF\spring.factories中获取SpringApplicationRunListener接口的实现类EventPublishingRunListener，主要发布SpringApplicationEvent
4. 把输入参数转成DefaultApplicationArguments类
5. 创建Environment并设置比如环境信息，系统熟悉，输入参数和profile信息
6. 打印Banner信息
7. 创建Application的上下文，根据WebApplicationTyp来创建Context类，如果非web项目则创建AnnotationConfigApplicationContext，在构造方法中初始化AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner
8. 在文件META-INF\spring.factories中获取SpringBootExceptionReporter接口的实现类FailureAnalyzers
9. 准备application的上下文
   1. 初始化ApplicationContextInitializer执行Initializer的contextPrepared方法，发布
   2. ApplicationContextInitializedEvent事件
   3. 如果延迟加载，在上下文添加处理器LazyInitializationBeanFactoryPostProcessor
   4. 执行加载方法，BeanDefinitionLoader.load方法，主要初始化了AnnotatedGenericBeanDefinition
   5. 执行Initializer的contextLoaded方法，发布ApplicationContextInitializedEvent事件

10.刷新上下文（后文会单独分析refresh方法），在这里真正加载bean到容器中。如果是web容器，会在onRefresh方法中创建一个Server并启动。

# 5.SpringBoot自动装配

自动装配选择器

SpringBoot在启动的时候，会根据META-INF包下的spring.factories

找到自动装配的类，他会把这个类加载到内存中，

这些自动装配的类有很多条件注解，

这些条件注解会根据我们引入的jar包以及我们自己注入的bean为条件完成自动装配



**详细：**

spring启动是依靠启动类的main方法进行启动的，在main方法中，会调用springapplication.run方法，在run方法执行的时候，其中会有一个刷新容器的过程，有一个refiscontext方法它会刷新容器，在刷新容器的时候，他会通过解释注解，解析配置文件的方式把我们的bean注到容器里面，这个时候他就会解析springapplication注解， 它本身是个配置类，里面有提个开启outConfigretion的注解，在这个注解里面，他有一个核心的东西，它import进来一个类，一个selecter类这个类是outConfigretionSelecter类,这个类有一些核心方法，会帮助我们从类路径下的META-INF下的spring.factories加载一些东西，会把key为_ ，这个key下面有很多的自动配置类，它会加载这个key下面的所有的配置类， 在这个outConfigretion类里面有很多条件注解，它会根据引入的jar包，容器里面的bean自动注入容器里面，实现了自动装配



spring启动的时候会调用run方法，run方法会刷新容器，会从类路径下找spring.factories文件

这个文件里，记录了很多的配置类，启动的时候将这些配置类加载到容器里面

这些自动装配的类有很多条件注解，

这些条件注解会根据我们引入的jar包以及我们自己注入的bean，自动的往容器里面注入很多的bean。

# 6.IOC

Ioc的实现：（控制反转）spring利用他的接口beanfactory这个接口，然后application context他是加载我们的配置文件，然后去创建我们的bean，然后去把它保存在我们的容器中，说白了就是动解析，然后是反射加工厂的方式去实现，能依赖注入，通过接口类型，或者名字，注入到我们的bean中





# 7.AOP

Aop的实现：它是一种思想

aop也就是动态代理，常见的两种动态代理，说白了就是jdk动态代理和cglib动态代理

当这个类有实现接口的时候用的式jdk      没有实现的时候用的cglib  cglib利用了ASM，通过对class文件，直接操作二进制编码，



1.@aspect：表明是切面类

3.//@Before("controllerAspect()")：表示拦截方法执行前的动作

4.@Around("controllerAspect()")：表示方法执行前后的动作，注意要有返回值

# 8.Spring与SpringBoot的区别

去配置化，boot的自动装配可以帮我们自动注入bean

# 8、SpringMVC的执行流程

1. 首先用户发送请求到DispatcherServlet**中央处理器**中，中央处理器会接收所有的请求，然后进行分发，
2. 它会分发给**处理器映射器**，把相应的**处理器执行链**、**处理器拦截器**、**处理器对象**这些东西给返回
3. 返回回去之后再调用**处理器适配器**，
4. **处理器适配器**在调用适配的**处理器**，
5. 然后再返回给**中央处理器**一个**视图和模型层**，
6. **中央处理器**再把这个**对象**分发到**视图解析器**中，
7. **视图解析器**中负责把数据和视图融合在一起，形成一个可以展示的**视图进行渲染**



1.用户发送请求至前端控制器DispatcherServlet
 2.DispatcherServlet收到请求调用处理器映射器HandlerMapping。
 3.处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。
 4.DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作
 5.执行处理器Handler(Controller，也叫页面控制器)。
 6.Handler执行完成返回ModelAndView
 7.HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet
 8.DispatcherServlet将ModelAndView传给ViewReslover视图解析器
 9.ViewReslover解析后返回具体View
 10.DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。
 11.DispatcherServlet响应用户。

# 8、hasmap和hastable的区别

1. 继承父类不同

2. 线程安全

3. 存null

4. 初始化容量

5. 扩容

6. hash值

7. 计算下标方式

8. 1.ht 的线程安全因为每个方法有锁   hm线程不安全
   2.继承的父类不同 ht dictionary   hm: 2
   3.对null  key 和null value的支持不同， ht: key  value不能为null
   hm:key value 可以为null  它是去判断哈希key的值，完了判断哈希值是否为null

   4.初始容器大小不一样  ht：11  hm：16
   5.ht 在调用构造方法时候初始化   hm在第一次添加调用put的时候再构建数组
   6.ht 扩容2n+1  hm 2倍
   7.下表的计算方式

    

9. hash值的方式不同，在hashtable中直接调用hashcode方法，在hashmap中先判断key等于null的话为0，如果key不为null的话直接计算他的hashcode并右移16位，

   通过取hask值并通过高位向右移进行异或运算进行获取hash值

# 9.Mybatis的缓存



### 一级缓存

Mybatis的一级缓存是指Session缓存。一级缓存的作用域默认是一个SqlSession。Mybatis默认开启一级缓存。

### 二级缓存

Mybatis的二级缓存是指mapper映射文件。二级缓存的作用域是同一个namespace下的mapper映射文件内容，多个SqlSession共享。Mybatis需要手动设置启动二级缓存。





# 10、Eureka的自我保护机制



### `Eureka Client` 每30秒来发送一次心跳来更新实例信息。

Eureka Server 在运行期间会去统计心跳失败比例在 15 分钟之内是否低于 85%，如果低于 85%，Eureka Server 会将这些实例保护起来，让这些实例不会过期，但是在保护期内如果服务刚好这个服务提供者非正常下线了，此时服务消费者就会拿到一个无效的服务实例，此时会调用失败，对于这个问题需要服务消费者端要有一些容错机制，如重试，断路器等。



# 10.es

### 底层 lucene

简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。

通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。



 

### 倒排索引

在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。例如，文档 1 经过分词，提取了 20 个关键词，每个关键词都会记录它在文档中出现的次数和出现位置。

 

那么，倒排索引就是关键词到文档 ID 的映射，每个关键词都对应着一系列的文件，这些文件中都出现了关键词。

# 10.GeteWay的启动流程



# 11.Eureka和Nacos的区别

#### Spring Cloud Nacos

##### 优点：

1）开箱即用，适用于dubbo，spring cloud等

2）AP模型，数据最终一致性

3）**注册中心，配置中心二合一(二合一也不一定是优点)，提供控制台管理**

4）**纯国产，各种有中文文档，久经双十一考验**

##### 缺点：

1）刚刚开源不久，社区热度不够，依然存在bug

#### Spring Cloud Eureka：

##### 优点：

1）**Spring Cloud 官方推荐**

2）AP模型，数据最终一致性

3）**开箱即用，具有控制台管理**

**Eureka官宣2.x版本不再开源**

##### 缺点：

1）**客户端注册服务上报所有信息，节点多的情况下，网络，服务端压力过大，且浪费内存**

2）客户端更新服务信息通过简单的轮询机制，当服务数量巨大时，服务器压力过大。

3）集群伸缩性不强，服务端集群通过广播式的复制，增加服务器压力



# zookeeper

## 12.Zookeeper是什么框架

分布式开源框架，提供分布式协调服务，解决了分布式一致性问题。原本是Hadoop、HBase的一个重要组件。

### 13.Zookeeper有哪几种节点类型

持久：创建之后一直存在，除非有删除操作，创建节点的客户端会话失效也不影响此节点。
持久顺序：持久节点名后缀加上一个10位数字。
临时：创建客户端会话失效（注意是会话失效，不是连接断了），节点也就没了。不能建子节点。
临时顺序：临时节点名后缀加上一个10位数字。



### 创建节点

create /test laogong // 创建永久节点 

create -e /test laogong // 创建临时节点

create -s /test // 创建顺序节点

create -e -s /test  // 创建临时顺序节点

### 14.Zookeeper对节点的watch监听通知是永久的吗？

不是。官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。
为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，这太消耗性能了。
一般是客户端执行getData(“/节点A”,true)，如果节点A发生了变更或删除，客户端会得到它的watch事件，但是在之后节点A又发生了变更，而客户端又没有设置watch事件，就不再给客户端发送。
在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。
部署方式？集群中的机器角色都有哪些？集群最少要几台机器

单机，集群，伪集群。Leader、Follower、Observer。集群最低3（2N+1）台，保证奇数，主要是为了选举算法。

### 15.集群如果有3台机器，挂掉一台集群还能工作吗？挂掉两台呢？

过半存活即可用。
集群支持动态添加机器吗？
其实就是水平扩容了，Zookeeper在这方面不太好。两种方式：
全部重启：关闭所有Zookeeper服务，修改配置之后启动。不影响之前客户端的会话。
逐个重启：这是比较常用的方式。



# RabbitMq

# 1、RabbitMQ和kafka的区别

**1.应用场景方面**
**RabbitMQ**：**用于实时的，对可靠性要求较高的消息传递上。**
**kafka**：**用于处于活跃的流式数据，大数据量的数据处理上。**

**2.架构模型方面**
producer，broker，consumer
**RabbitMQ：以broker为中心，有消息的确认机制**
**kafka：以consumer为中心，无消息的确认机制**

**3.吞吐量方面**
**RabbitMQ**：**支持消息的可靠的传递，支持事务，不支持批量操作**，基于存储的可靠性的要求存储可以采用内存或硬盘，**吞吐量小**。
kafka：内部采用消息的批量处理，数据的存储和获取是本地磁盘顺序批量操作，消息处理的效率高，吞吐量高。

**4.集群负载均衡方面**
RabbitMQ：本身不支持负载均衡，需要loadbalancer的支持
kafka：采用zookeeper对集群中的broker，consumer进行管理，可以注册topic到zookeeper上，通过zookeeper的协调机制，producer保存对应的topic的broker信息，可以随机或者轮询发送到broker上，producer可以基于语义指定分片，消息发送到broker的某个分片上。

### 1、什么是RabbitMQ？为什么使用RabbitMQ？

答：RabbitMQ是一款开源的，Erlang编写的，基于AMQP协议的，消息中间件；

可以用它来：解耦、异步、削峰。

 

##### 2、RabbitMQ有什么优缺点？

答：优点：解耦、异步、削峰；

缺点：降低了系统的稳定性：本来系统运行好好的，现在你非要加入个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性会降低；

增加了系统的复杂性：加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。

 

##### 3、如何保证RabbitMQ的高可用？

答：没有哪个项目会只用一搭建一台RabbitMQ服务器提供服务，风险太大；

 

##### 

##### 4、如何保证RabbitMQ不被重复消费？

答：先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；

但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；

比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；

 

##### 5、如何保证RabbitMQ消息的可靠传输？

答：消息不可靠的情况可能是消息丢失，劫持等原因；

丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；

 

生产者丢失消息：从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；

transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。然而，这种方式有个缺点：吞吐量下降；

confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；

rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；

如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

 

消息队列丢数据：消息持久化。

处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。

这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。

这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。

那么如何持久化呢？

这里顺便说一下吧，其实也很容易，就下面两步

1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列
2. 发送消息的时候将deliveryMode=2

这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据

 

消费者丢失消息：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！

消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；

如果这时处理消息失败，就会丢失该消息；

解决方案：处理消息成功后，手动回复确认消息。

 

##### 6、如何保证RabbitMQ消息的顺序性？

答：单线程消费保证消息的顺序性；对消息进行编号，消费者处理消息是根据编号处理消息；



#### 7、rebbitMQ消息堆积    重复消费  消息丢失

多跑几个服务器去消费

这是幂等性的问题  在数据库主键佳唯一约束

3:

生产者丢：开事务，confier机制

mq丢：持久化   刷盘操作  25毫秒    数据写磁盘     ，  镜像队列高可用

消费者丢：手动ACK  



# 16、如何在Java中实现线程(4种)？

1.继承Thread类，重写run方法（其实Thread类本身也实现了Runnable接口）

2.实现Runnable接口，重写run方法

3.实现Callable接口，重写call方法（有返回值） Excutr接返回值

4.使用线程池（有返回值）

# 18、在具体多线程编程实践中，如何选用Runnable还是Thread？

在程序开发中只要是多线程，肯定永远以实现Runnable接口

 1、可以避免由于Java的单继承特性而带来的局限；

 2、增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的；

 3、适合多个相同程序代码的线程区处理同一资源的情况。



# 18.rpc远程调用

比如 A (client) 调用 B (server) 提供的remoteAdd方法：
 首先A与B之间建立一个TCP连接；
 然后A把需要调用的方法名（这里是remoteAdd）以及方法参数（10， 20）序列化成字节流发送出去；
 B接受A发送过来的字节流，然后反序列化得到目标方法名，方法参数，接着执行相应的方法调用（可能是localAdd）并把结果30返回；A接受远程调用结果,输出30。





# 19、Java中Runnable和Callable有什么不同

1. 两者最大的不同点是：实现Callable接口的任务线程能返回执行结果；而实现Runnable接口的任务线程不能返回结果；

2. Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛；


# 20、如何避免死锁？ 

1. 加锁顺序

按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁(并对这些锁做适当的排序)，但总有些时候是无法预知的。

2. 加锁时限

另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。

3.死锁检测

每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。

# 21.Java多线程中调用wait() 和 sleep()方法有什么不同?

sleep()属于Thread类的方法。wait()属于Object类的方法，

sleep()方法没有释放锁，而wait()方法释放了锁，

# 22、什么是多线程中的上下文切换？

CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换。

24.se

# 22、lock和sychronize的区别



首先synchronized是java内置关键字，在jvm层面，Lock是个java类；

1.lock可实现公平锁

2.lock可以响应中断

3.限时等待。

都具有可重入性。





# 23、什么是线程安全

线程安全的代码是多个线程同时执行也能工作的代码

如果一段代码可以保证多个线程访问的时候正确操作共享数据，那么它是线程安全的

# 24、多线程的应用场景

应用场景：1.tomcat服务器
​		2.后台任务：任务量较大时  用多线程节省时间
​		3.异步处理：统计结果，记录日志，发短信等与用户无关的操作
​		4.分布式计算；分片上传下载，断点续传

# 24.线程池四种创建方式

Java通过Executors（jdk1.5并发包）提供四种线程池，分别为：

##### 1.newCachedThreadPool

newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。  

##### 2.newFixedThreadPool

newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 有一个无界队列，回造成oom内存溢出

##### 3.newScheduledThreadPoo

newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。 无界队列

##### 4.newSingleThreadExecutor

newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 无界队列



都不能起名字

会发生oom内存溢出

无界队列



# 25、线程池有哪些种类，各自的使用场景是什么？

**1.newCachedThreadPool：**

 底层：返回ThreadPoolExecutor实例，corePoolSize为0；maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为60L；unit为TimeUnit.SECONDS；workQueue为SynchronousQueue(同步队列)

 通俗：当有新任务到来，则插入到SynchronousQueue中，由于SynchronousQueue是同步队列，因此会在池中寻找可用线程来执行，若有可以线程则执行，若没有可用线程则创建一个线程来执行该任务；若池中线程空闲时间超过指定大小，则该线程会被销毁。

 适用：执行很多短期异步的小程序或者负载较轻的服务器

**2.newFixedThreadPool：**

 底层：返回ThreadPoolExecutor实例，接收参数为所设定线程数量nThread，corePoolSize为nThread，maximumPoolSize为nThread；keepAliveTime为0L(不限时)；unit为：TimeUnit.MILLISECONDS；WorkQueue为：new LinkedBlockingQueue<Runnable>() 无解阻塞队列

 通俗：创建可容纳固定数量线程的池子，每隔线程的存活时间是无限的，当池子满了就不在添加线程了；如果池中的所有线程均在繁忙状态，对于新任务会进入阻塞队列中(无界的阻塞队列)

 适用：执行长期的任务，性能好很多

**3.newSingleThreadExecutor:**

 底层：FinalizableDelegatedExecutorService包装的ThreadPoolExecutor实例，corePoolSize为1；maximumPoolSize为1；keepAliveTime为0L；unit为：TimeUnit.MILLISECONDS；workQueue为：new LinkedBlockingQueue<Runnable>() 无解阻塞队列

 通俗：创建只有一个线程的线程池，且线程的存活时间是无限的；当该线程正繁忙时，对于新任务会进入阻塞队列中(无界的阻塞队列)

 适用：一个任务一个任务执行的场景

**4.NewScheduledThreadPool:**

 底层：创建ScheduledThreadPoolExecutor实例，corePoolSize为传递来的参数，maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为0；unit为：TimeUnit.NANOSECONDS；workQueue为：new DelayedWorkQueue() 一个按超时时间升序排序的队列

 通俗：创建一个固定大小的线程池，线程池内线程存活时间无限制，线程池可以支持定时及周期性任务执行，如果所有线程均处于繁忙状态，对于新任务会进入DelayedWorkQueue队列中，这是一种按照超时时间排序的队列结构

 适用：周期性执行任务的场景

# 26、线程池有哪些重要的参数？

1. corePoolSize：线程池中常驻核心线程数
2. maximumPoolSize：线程池能够容纳同时执行的最大线程数，此值必须大于等于1，读音[ˈmæksɪməm]咩西门-最大限度
3. keepAliveTime：多余的空闲线程存活时间。当前线程池数量超过corePoolSize时，当空闲时间到达keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止。
4. unit：keepAliveTime的时间单位
5. workQueue：任务队列，被提交但尚未执行的任务
6. threadFactory：表示生成线程池中的工作线程的线程工厂，用于创建线程，一般为默认线程工厂即可
7. handler：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来拒绝来请求的Runnable的策略



# 27、多线程的拒绝策略

```
它将抛出 RejectedExecutionException 异常
```





# 29、如何在多个线程间共享数据？

如果每个线程执行的代码相同，可以使用同一个Runnable对象，这个Runnable对象中有那个共享数据，



# 29、多线程的CAS

### 比较并交换

### 1、CAS算法理解

计算机cpu原子级别的原子： 比较并交换

对CAS的理解，CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

### **2.ABA的问题**

我将内存种的1改为3之后进行了一系列的操作又改为了1，另一个线程进来后预期值为1，就又去操作了，这就是ABA问题，解决这个问题就是加版本号



hashmap和list的线程安全问题 

rest和rpc



# 30、服务熔断降级

1、**服务熔断**一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护；**服务熔断**一般是某个服务（下游服务）故障引起，而**服务降级**一般是从整体负荷考虑；**熔断**其实是一个框架级的处理，每个微服务都需要（无层级之分），而**降级**一般需要对业务有层级之分（比如**降级**一般是从最外围服务开始）



# 21、分布式事务

### 1.seate

一ID+三组件

1. id
   全局唯一的事务ID
2. 3组件

- **事务协调器（TC）Transaction Coordinator：**维护全局事务和分支事务的状态，驱动全局提交或回滚。它是独立的中间件，需要独立部署运行，它维护全局事务的运行状态，接收TM指令发起全局事务的提交与回滚，负责与RM通信协调各各分支事务的提交或回滚。

- **事务管理器（TM）    Transaction Manager：**定义全局事务的范围：负责开启全局事务，并最终 向TC发起全局提交或全局回滚的指令。

- **资源管理器（RM）  Resource Manager ：**管理分支事务正在处理的资源，与TC进行对话以注册分支事务并报告分支事务的状态，并驱动分支事务的提交或回滚。

- 事务管理器TM向事务协调器TC申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID

- XID在微服务调用链路的上下文中传播

- 资源管理器RM向事务协调器TC注册分支事务，将其纳入XID对应全局事务的管辖

- 事务管理器TM 向事务协调器 TC 发起针对 XID 的全局提交或回滚请求

- 事务协调器TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求


### 2.TCC分布式事务

TCC是服务化的两阶段编程模型，其Try、Confirm、Cancel，3个方法均由业务编码实现。TCC要求每个分支事务实现三个操作：预处理Try、确认 Confirm、撤销Cancel。==Try操作做业务检查及资源预留，Confirm做业务确认操作，Cancel实现一个与Try相反的 操作即回滚操作。==TM首先发起所有的分支事务的try操作，任何一个分支事务的try操作执行失败，TM将会发起所 有分支事务的Cancel操作，若try操作全部成功，TM将会发起所有分支事务的Confirm操作，其中Confirm/Cancel 操作若执行失败，TM会进行重试。

### **3.TCC的三个阶段**

- Try 阶段是做业务检查(一致性)及资源预留(隔离)，此阶段仅是一个初步操作，它和后续的Confirm一起才能 真正构成一个完整的业务逻辑。
- Confirm阶段是做确认提交，Try阶段所有分支事务执行成功后开始执行 Confirm。通常情况下，采用TCC则认为 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。若Confirm阶段真的出错了，需引 入重试机制或人工处理。 
- Cancel 阶段是在业务执行错误需要回滚的状态下执行分支事务的业务取消，预留资源释放。通常情况下，采 用TCC则认为Cancel阶段也是一定成功的。若Cancel阶段真的出错了，需引入重试机制或人工处理。

### **4.TCC的三种异常处理情况**

幂等处理

- 因为网络抖动等原因，分布式事务框架可能会重复调用同一个分布式事务中的一个分支事务的二阶段接口。所以分支事务的二阶段接口try/Confirm/Cancel需要能够保证幂等性。如果二阶段接口不能保证幂等性，则会产生严重的问题，造成资源的重复使用或者重复释放，进而导致业务故障。

空回滚

- 当没有调用TCC资源Try方法的情况下，就调用了二阶段的Cancel方法，Cancel方法需要有办法识别出此时Try有没有执行。如果Try还没执行，表示这个Cancel操作是无效的，即本次Cancel属于空回滚；如果Try已经执行，那么执行的是正常的回滚逻辑。
- 要应对空回滚的问题，就需要让参与者在二阶段的Cancel方法中有办法识别到一阶段的Try是否已经执行。很显然，可以继续利用事务状态控制表来实现这个功能。
- 当Try方法被成功执行后，会插入一条记录，标识该分支事务处于INIT状态。所以后续当二阶段的Cancel方法被调用时，可以通过查询控制表的对应记录进行判断。如果记录存在且状态为INIT，就表示一阶段已成功执行，可以正常执行回滚操作，释放预留的资源；如果记录不存在则表示一阶段未执行，本次为空回滚，不释放任何资源。



悬挂

- 问题：二阶段回滚方法比一阶段 try 方法先执行。
- 解决：事务状态控制记录作为控制手段，二阶段发现无记录时插入记录，一阶段执行时检查记录是否存在



### 5.最大努力通知

目标：发起通知方通过一定的机制最大努力将业务处理结果通知到接收方。

==消息重复通知机制==

因为接收通知方可能没有接收到通知，此时要有一定的机制对消息重复通知。 

==消息校对机制==

如果尽最大努力也没有通知到接收方，或者接收方消费消息后要再次消费，此时可由接收方主动向通知方查询信息来满足需求。

### 解决方案 

通过对最大努力通知的理解，采用MQ的ack机制就可以实现最大努力通知。



### 6.分布式事务方案对比分析

- 2PC 最大的一个诟病是一个阻塞协议。RM在执行分支事务后需要等待TM的决定，此时服务会阻塞锁定资源。由于其阻塞机制和最差时间复杂度高，因此，这种设计不能适应随着事务涉及的服务数量增加而扩展的需要，很难用于并发较高以及子事务生命周期较长的分布式服务中
- 如果拿TCC事务的处理流程与2PC两阶段提交做比较，2PC通常都是在跨库的DB层面，而TCC则在应用层面处理，需要通过业务逻辑来实现。这种分布式事务的优势在于，可以让应用自定义数据操作的粒度，使得降低锁冲突，提高吞吐量成为可能。而不足之处在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现三个操作。此外，其实现难度也比较大，需要按照网络状态，系统故障等不同失败原因实现不同的策略。
- 可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作，避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦，典型的场景：注册送积分，登陆送优惠券等
- 最大努力通知是分布式事务中要求最低的一种，适用于一些最终一致性时间敏感度低的业务，允许发起通知方业务处理失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都不会影响到接收通知方的后续处理，发起通知方需提供查询执行情况接口，用于接收通知方校对结果，典型的应用场景：银行通知，支付结果通知等。

# 22、分布式锁：

- - Redis分布式锁

  - - RedLock算法

    - - 1）获取当前时间戳，单位是毫秒
      - 2）跟上面类似，轮流尝试在每个master节点上创建锁，过期时间较短，一般就几十毫秒
      - 3）尝试在大多数节点上建立一个锁，比如5个节点就要求是3个节点（n / 2 +1）
      - 4）客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了
      - 5）要是锁建立失败了，那么就依次删除这个锁
      - 6）只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁

    - 互斥、不能死锁、容错

    - lua脚本执行操作

    - SET my:lock随机值NX PX 30000

  - zk分布式锁

  - - 获取锁时，创建临时节点

    - 没获取到注册监听器

    - 基于zookeeper临时顺序节点实现分布式锁：（优雅）

    - - 监听前一个节点

  - redis分布式锁和zk分布式锁对比：

  - - redis：自己不断去尝试获取锁，消耗性能；宕机时等待超时
    - zk：注册监听器，性能开销小；宕机时临时节点消失

# 22.reids

##### 1.redis的数据结构

字符串(strings)，哈希表(hashes)，列表(lists)，集合(sets)，有序集合(sorted sets)等等。”

##### 2.redis的淘汰策略

介绍

- 当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。交换会让 Redis 的性能急剧下降，

- Redis在生产环境中，采用配置参数maxmemory 的方式来限制内存大小。

- 首先，客户端会发起需要更多内存的申请；

  其次，Redis检查内存使用情况，如果实际使用内存已经超出maxmemory，Redis就会根据用户配置的淘汰策略选出无用的key；

  最后，确认选中数据没有问题，成功执行淘汰任务。

1. volatile-lru：从设置过期时间的数据集（server.db[i].expires）中挑选出最近最少使用的数据淘汰。
2.  volatile-ttl：除了淘汰机制采用LRU，策略基本上与volatile-lru相似，从设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰，ttl值越大越优先被淘汰。
3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。
4. allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰，该策略要淘汰的key面向的是全体key集合，而非过期的key集合。
5. allkeys-random：从数据集(server.db[i].dict）中选择任意数据淘汰。
6. no-enviction：禁止驱逐数据，也就是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失，这也是系统默认的一种淘汰策略。

##### 3.redis的持久化策略

- 快照：RDB（数据快照模式），定期存储，保存的是数据本身，存储文件是紧凑的
- 日志：AOF（追加模式），每次修改数据时，同步到硬盘(写操作日志)，保存的是数据的变更记录
- 如果只希望数据保存在内存中的话，俩种策略都可以关闭
- 也可以同时开启俩种策略，当Redis重启时，AOF文件会用于重建原始数据
- <https://blog.csdn.net/q649381130/article/details/79920277>



##### 4.redis的优缺点

**优点**

1 读写性能优异

2 支持数据持久化，支持AOF和RDB两种持久化方式

3 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。

4 [数据结构](http://lib.csdn.net/base/datastructure)丰富：除了支持string类型的value外还支持string、hash、set、sortedset、list等数据结构。

**缺点**

1.Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

2.[Redis]主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。



##### 5.redis的缓存穿透

key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。



##### 5.redis的缓存击穿

key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。



##### 5.redis的缓存雪崩

当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。



##### 6.redis的主从复制

**主(master)"**和**"从(slave)"**

主服务器既可以读也可以写，而从服务器原则上只允许读操作(通过修改配置，从服务器也可以执行写入操作)，同时负责接收和同步主服务器上的数据。主服务器和从服务器是一对多的关系，



##### 7.redis的哨兵模式

在主从模式的[Redis](https://cloud.tencent.com/product/crs?from=10680)系统中，从数据库在整个系统中起到了数据冗余备份和读写分离的作用，但是当数据库遇到异常中断服务后，我们只能通过手动的方式选择一个从数据库来升格为主数据库，

当启动哨兵模式之后，如果你的master服务器宕机之后，哨兵自动会在从redis服务器里面 投票选举一个master主服务器出来；这个主服务器也可以进行**读写**操作！

sentinel节点会定期向master节点发送心跳包来判断存活状态，一旦master节点没有正确响应，sentinel会把master设置为“主观不可用状态”，然后它会把“主观不可用”发送给其他所有的sentinel节点去确认，当确认的sentinel节点数大于>quorum时，则会认为master是“客观不可用”，接着就开始进入选举新的master流程；

这个时候就需要从sentinel集群中选择一个leader来做决策。而这里用到了一致性算法Raft算法.

##### 8.redis能做什么

1. 缓存，毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效；

2. 排行榜，如果使用传统的关系型数据库来做这个事儿，非常的麻烦，而利用Redis的SortSet数据结构能够非常方便搞定；

3. 计算器/限速器，利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；

   注：限速器也是对请求限流的一种实现方式。

4. 好友关系，利用集合的一些命令，比如求交集、并集、差集等。可以方便搞定一些共同好友、共同爱好之类的功能；

5. 简单消息队列，除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦；

6. Session共享，默认Session是保存在服务器的文件中，即当前服务器，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。

token  数据字典  权限  

# 23设计模式

#### 单例设计模式

懒汉式

在高并发的情况下 会有问题 用的是DNCL双重检查锁，线去判断有没有这哥实例对象没有的话一个一个进锁，第一个进去new出来了，之后的就发现以及new出来了，就返回了不进了

饿汉式

#### 代理设计模式

##### 静态代理模式

代理类接受一个Subject接口的对象，任何实现该接口的对象，都可以通过代理类进行代理，增加了通用性。

但是也有缺点，每一个代理类都必须实现一遍委托类（也就是realsubject）的接口，如果接口增加方法，则代理类也必须跟着修改。

##### 动态代理

是根据代理的对象，动态创建代理类。动态代理的实现方式，是通过反射来实现的，借助Java自带的，实现`InvocationHandler`接口，并重写该`invoke`方法,通过固定的规则生成。

1. 编写一个委托类的接口，即静态代理的（Subject接口）
2. 实现一个真正的委托类，即静态代理的（RealSubject类）
3. 创建一个动态代理类，实现`InvocationHandler`接口，并重写该`invoke`方法
4. 在测试类中，生成动态代理的对象。

#### 工厂设计模式

##### 简单工厂设计模式

苹果和梨都属于水果，抽象出来一个水果类Fruit，苹果和梨就是具体的产品类，然后创建一个水果工厂类，

有局限性，我还想生产橘子，香蕉，就必然要修改工厂类，这显然违反了开闭原则，



##### 工厂方法设计模式

产品类抽象出来，这次我们把工厂类也抽象出来，生产什么样的产品由子类来决定；就是生产苹果有苹果的生产工厂，生产香蕉有香蕉的生产工厂，

虽然解耦了，也遵循了开闭原则，但是问题根本还是没有解决啊，换汤没换药，如果我需要的产品很多的话，需要创建非常多的工厂



##### 抽象工厂设计模式

工厂方法是生产一个具体的产品，而抽象工厂可以用来生产一组相同，有相对关系的产品；重点在于一组，一批，一系列；

抽象工厂用来解决相对复杂的问题，适用于一系列、大批量的对象生产；



# 24.生命周期

### 1.bean的生命周期

1. 构造 
2. 注入 
3. 初始化 
4. 使用 
5. 销毁

### 2.servlet的生命周期

加载类—>实例化(为对象分配空间)—>初始化(为对象的属性赋值)—>请求处理(服务阶段)—>销毁

### 3.线程的生命周期

- 新建：就是刚使用new方法，new出来的线程；
- 就绪：就是调用的线程的start()方法后，这时候线程处于等待CPU分配资源阶段，谁先抢的CPU资源，谁开始执行;
- 运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能;
- 阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态;
- 销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源;

### 4.maven的生命周期

maven的生命周期就是对所有构建过程抽象与统一，生命周期包含项目的清理、初始化、编译、测试、打包、集成测试、验证、部署、站点生成等几乎所有的过程。

Maven 有三套相互独立的生命周期：
1）CleanLifecycle 在进行真正的构建之前进行一些清理工作。
2）DefaultLifecycle 构建的核心部分，编译，测试，打包，部署等等。
3）SiteLifecycle 生成项目报告，站点，发布站点。



# 分布式锁的实现

分布式锁有三种实现方式，

1. ### mysql的事务

2. **redi的sredisssion框架，其中用到的是setNx方法**，获取一个redission的实例，然后.get后lock.lock,lock.unlock就可以解决

3. ### zookeeper的临时顺序节点

   都可以实现分布式锁

我们常用zookeeper的临时顺序节点做分布式锁，zookeeper中每个服务首先会向zookeeper进行注册，注册的时候获取到event监听比他小的另一个节点，当另一个节点释放资源的时候，这边就会监听到数据丢失，当前这个节点就会去访问资源



# Seata分布式事务

Seata有三个组成部分：事务协调器TC：协调者、事务管理器TM：发起方、资源管理器RM：参与方
（1）发起方会向协调者申请一个全局事务id，并保存到ThreadLocal中（为什么要保存到ThreadLocal中？弱引用，线程之间不会发生数据冲突）
（2）Seata数据源代理发起方和参与方的数据源，将前置镜像和后置镜像写入到undo_log表中，方便后期回滚使用
（3）发起方获取全局事务id，通过改写Feign客户端请求头传入全局事务id。
（4）参与方从请求头中获取全局事务id保存到ThreadLocal中，并把该分支注册到SeataServer中。
（5）如果没有出现异常，发起方会通知协调者，协调者通知所有分支，通过全局事务id和本地事务id删除undo_log数据，如果出现异常，通过undo_log逆向生成sql语句并执行，然后删除undo_log语句。如果处理业务逻辑代码超时，也会回滚。



# 25、秒杀

Nginx首先要通过令牌桶算法或者漏桶算法进行限流，网关限流，访问秒杀接口为了防止磁盘io，我们要用到
redis，将库存放进redis里的list里生成一个令牌，当进一个线程令牌减一，库存减一，
将这个消息发给mq，mq直接响应抢购成功，mq里面的交换机对应n个队列，然后让多个订单服务区处理，
成功之后，点付款的时候，就要去订单服务里面根据用户id和商品id查回查接口，如果订单已经生成
说明抢购成功，可以支付了，完了再看有多少人支付了，将redis里的库存写进数据库，



# 26、防止表单重复提交

我们为了防止表单重复提交，一般前后都要做一些操作，一般会在后台写一个过滤器，或者是拦截器，当重定向页面跳转这个请求跳转到后台时，首先会经过滤器，这个过滤器会在session里面加入一个token，同时页面跳转之后，我们会在我们页面表单里面把这个token以一个隐藏域的形式进行存储，当我们的表单进行提交的时候，第一次提交，我们会把这个token携带上，到了后台经过过滤器，此时session里面有token，携带的参数里面又有token，过滤器会判断一下，两个token是不是一致，如果是一致，就把请求放行，当然有的会点击按钮的时候会点击好几下，会导致发送多个请求，第一个请求再对比完成放行之后，会把session里面的token删掉，那么以后进来的请求，过滤器还会拦截并比较token，，此时session里面没token了，第二次和第二次以后的请求就都会被拦截下来



 

rbac 用户的5张表 基于权限  用户角色权限按钮（中间表）    增删查改写出来   给用户赋角色  给角色赋权限    

写注解 AOP切面加个注解    注解的所有方法弄一个环绕通知   判断用户所有的权限  在不在传过来的数组里面 

认证：登陆成功    授权：访问方法有没有权限  



AOP，文档的导出，权限，日志，事务，







# 